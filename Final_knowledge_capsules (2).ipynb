{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing modules and visualization tools"
      ],
      "metadata": {
        "id": "Ar4soGJCPFIB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5aBDu7FNBMk",
        "outputId": "007dc345-ff4a-4b8d-9bfe-bd4d27020f6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Core imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import uuid\n",
        "import time\n",
        "from collections import Counter\n",
        "\n",
        "# For ML tasks\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Optional: Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/My Drive/Capsule'\n"
      ],
      "metadata": {
        "id": "DlOQN9L_PkgW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class defining data capsule structure"
      ],
      "metadata": {
        "id": "7uM0Ov-RR1sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DataCapsule encapsulates sample-level features and metadata\n",
        "class DataCapsule:\n",
        "    def __init__(self, capsule_id, features, label,\n",
        "                 confidence=None, rare=False, source_id=None, timestamp=None):\n",
        "        self.id = capsule_id\n",
        "        self.features = features  # numpy array\n",
        "        self.label = label\n",
        "        self.confidence = confidence\n",
        "        self.rare = rare\n",
        "        self.source_id = source_id\n",
        "        self.timestamp = timestamp or time.time()\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"id\": self.id,\n",
        "            \"type\": \"data\",\n",
        "            \"features\": self.features.tolist(),\n",
        "            \"label\": self.label,\n",
        "            \"confidence\": self.confidence,\n",
        "            \"rare\": self.rare,\n",
        "            \"source_id\": self.source_id,\n",
        "            \"timestamp\": self.timestamp\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def from_dict(data):\n",
        "        return DataCapsule(\n",
        "            capsule_id=data[\"id\"],\n",
        "            features=np.array(data[\"features\"]),\n",
        "            label=data[\"label\"],\n",
        "            confidence=data[\"confidence\"],\n",
        "            rare=data[\"rare\"],\n",
        "            source_id=data[\"source_id\"],\n",
        "            timestamp=data[\"timestamp\"]\n",
        "        )\n"
      ],
      "metadata": {
        "id": "XwZuQ0mTQqQc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class defining model capsule structure"
      ],
      "metadata": {
        "id": "iX4-Y4WMSBbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ModelCapsule encapsulates model-level metadata, summaries, and relevant references\n",
        "class ModelCapsule:\n",
        "    def __init__(self, capsule_id, model_summary,\n",
        "                 high_conf_data_ids=None, rare_data_ids=None,\n",
        "                 source_id=None, timestamp=None):\n",
        "        self.id = capsule_id\n",
        "        self.model_summary = model_summary  # e.g. weights, accuracy, label dist\n",
        "        self.high_conf_data_ids = high_conf_data_ids or []\n",
        "        self.rare_data_ids = rare_data_ids or []\n",
        "        self.source_id = source_id\n",
        "        self.timestamp = timestamp or time.time()\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"id\": self.id,\n",
        "            \"type\": \"model\",\n",
        "            \"model_summary\": self.model_summary,\n",
        "            \"high_conf_data_ids\": self.high_conf_data_ids,\n",
        "            \"rare_data_ids\": self.rare_data_ids,\n",
        "            \"source_id\": self.source_id,\n",
        "            \"timestamp\": self.timestamp\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def from_dict(data):\n",
        "        return ModelCapsule(\n",
        "            capsule_id=data[\"id\"],\n",
        "            model_summary=data[\"model_summary\"],\n",
        "            high_conf_data_ids=data.get(\"high_conf_data_ids\", []),\n",
        "            rare_data_ids=data.get(\"rare_data_ids\", []),\n",
        "            source_id=data.get(\"source_id\"),\n",
        "            timestamp=data[\"timestamp\"]\n",
        "        )\n"
      ],
      "metadata": {
        "id": "C8te3EyvR7sj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save & Load Utility"
      ],
      "metadata": {
        "id": "ALETQvnTSRJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_capsule(capsule, folder_path):\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    with open(os.path.join(folder_path, f\"{capsule.id}.json\"), \"w\") as f:\n",
        "        json.dump(capsule.to_dict(), f)\n",
        "\n",
        "def load_capsules(folder_path, capsule_type=\"data\"):\n",
        "    capsules = []\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith(\".json\"):\n",
        "            with open(os.path.join(folder_path, file_name), \"r\") as f:\n",
        "                data = json.load(f)\n",
        "                if capsule_type == \"data\" and data[\"type\"] == \"data\":\n",
        "                    capsules.append(DataCapsule.from_dict(data))\n",
        "                elif capsule_type == \"model\" and data[\"type\"] == \"model\":\n",
        "                    capsules.append(ModelCapsule.from_dict(data))\n",
        "    return capsules\n"
      ],
      "metadata": {
        "id": "z5XDhDauSGy6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset → Extract features (via PCA) → Create & store Data Capsules"
      ],
      "metadata": {
        "id": "OeqqcqyETH1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import uuid\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Step 1: Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Step 2: Apply PCA for compressed representation\n",
        "pca = PCA(n_components=10)\n",
        "X_reduced = pca.fit_transform(X)\n",
        "\n",
        "# Step 3: Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "QKlI_N89SYTg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate & Save Data Capsules"
      ],
      "metadata": {
        "id": "yIUFYLq8TQrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_capsules = []\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "    capsule_id = str(uuid.uuid4())\n",
        "    features = X_train[i]\n",
        "    label = int(y_train[i])\n",
        "    confidence = 1.0  # You can replace this later with predicted confidence scores\n",
        "\n",
        "    capsule = DataCapsule(\n",
        "        capsule_id=capsule_id,\n",
        "        features=features,\n",
        "        label=label,\n",
        "        confidence=confidence,\n",
        "        source_id=\"client_1\"\n",
        "    )\n",
        "\n",
        "    data_capsules.append(capsule)\n",
        "    save_capsule(capsule, folder_path)\n"
      ],
      "metadata": {
        "id": "x3T2tAYATLhv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load saved Data Capsules → Reconstruct training dataset → Train a simple classifier"
      ],
      "metadata": {
        "id": "8UpDjMZHUFVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load capsules from disk\n",
        "loaded_capsules = load_capsules(folder_path, capsule_type=\"data\")\n",
        "\n",
        "# Reconstruct features and labels\n",
        "X_capsules = np.array([cap.features for cap in loaded_capsules])\n",
        "y_capsules = np.array([cap.label for cap in loaded_capsules])\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_capsules, y_capsules)\n",
        "\n",
        "# Predict on test set (which we already PCA-compressed earlier)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy on held-out test set: {acc:.4f}\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8VEPMxqTTQU",
        "outputId": "0d691f6c-fe5f-41e5-90b0-1f8570964f70"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on held-out test set: 0.9561\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94        43\n",
            "           1       0.95      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Model Capsules\n",
        "\n",
        "Define a ModelCapsule class"
      ],
      "metadata": {
        "id": "EZ7B9e8YWEo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelCapsule:\n",
        "    def __init__(self,\n",
        "                 model_id=None,\n",
        "                 model_type=\"LogisticRegression\",\n",
        "                 accuracy=None,\n",
        "                 capsule_ids=None,\n",
        "                 high_conf_capsules=None,\n",
        "                 rare_capsules=None,\n",
        "                 weights=None,\n",
        "                 intercept=None,\n",
        "                 created_at=None):\n",
        "        self.model_id = model_id or str(uuid.uuid4())\n",
        "        self.model_type = model_type\n",
        "        self.accuracy = accuracy\n",
        "        self.capsule_ids = capsule_ids or []\n",
        "        self.high_conf_capsules = high_conf_capsules or []\n",
        "        self.rare_capsules = rare_capsules or []\n",
        "        self.weights = weights  # list of floats\n",
        "        self.intercept = intercept  # float\n",
        "        self.created_at = created_at or datetime.datetime.utcnow().isoformat()\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"model_id\": self.model_id,\n",
        "            \"model_type\": self.model_type,\n",
        "            \"accuracy\": self.accuracy,\n",
        "            \"capsule_ids\": self.capsule_ids,\n",
        "            \"high_conf_capsules\": self.high_conf_capsules,\n",
        "            \"rare_capsules\": self.rare_capsules,\n",
        "            \"weights\": self.weights,\n",
        "            \"intercept\": self.intercept,\n",
        "            \"created_at\": self.created_at\n",
        "        }\n",
        "\n",
        "    def save(self, folder_path):\n",
        "        path = os.path.join(folder_path, f\"{self.model_id}_model_capsule.json\")\n",
        "        with open(path, 'w') as f:\n",
        "            json.dump(self.to_dict(), f, indent=4)\n",
        "        print(f\"Saved model capsule with weights to {path}\")\n"
      ],
      "metadata": {
        "id": "wLOt-fgpU-IL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Capture weights from your model"
      ],
      "metadata": {
        "id": "UOfju1mAeZBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract model weights and intercept\n",
        "weights_list = clf.coef_.flatten().tolist()\n",
        "intercept_val = float(clf.intercept_[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "sBKVXjUEeYd0"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate a model capsule from current training"
      ],
      "metadata": {
        "id": "uNgAN1WPXC8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Determine high-confidence capsules\n",
        "# We'll mark all correctly predicted samples as high-confidence for now\n",
        "\n",
        "high_conf_ids = []\n",
        "for i, (x_feat, y_true, capsule) in enumerate(zip(X_capsules, y_capsules, loaded_capsules)):\n",
        "    y_pred = clf.predict([x_feat])[0]\n",
        "    if y_pred == y_true:\n",
        "        high_conf_ids.append(capsule.id)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hAXmodGkXB1K"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assign “rare = True” to selected capsules\n",
        "\n",
        "Hybrid-Based Rarity (Simple and Practical)\n",
        "Let's define rare classes as those that occur with low frequency (e.g., < 10% of all samples)."
      ],
      "metadata": {
        "id": "mo7lqqtje0l0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature outlier score\n",
        "from sklearn.covariance import MinCovDet\n",
        "robust_cov = MinCovDet().fit(X_capsules)\n",
        "mahalanobis_dist = robust_cov.mahalanobis(X_capsules)\n",
        "\n",
        "# Confidence-based uncertainty\n",
        "probs = clf.predict_proba(X_capsules)\n",
        "max_conf = np.max(probs, axis=1)\n",
        "\n",
        "# Frequency score\n",
        "from collections import Counter\n",
        "label_freq = Counter(cap.label for cap in loaded_capsules)\n",
        "label_ratio = [label_freq[cap.label]/len(loaded_capsules) for cap in loaded_capsules]\n",
        "\n",
        "# Mark rare\n",
        "for cap, dist, conf, freq in zip(loaded_capsules, mahalanobis_dist, max_conf, label_ratio):\n",
        "    cap.rare = (dist > np.percentile(mahalanobis_dist, 90)) or \\\n",
        "               (conf < 0.6) or \\\n",
        "               (freq < 0.1)\n",
        "\n"
      ],
      "metadata": {
        "id": "A7TiNaNQXvsT"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract rare capsule IDs"
      ],
      "metadata": {
        "id": "5-icCmKcgBDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7.1: Extract rare capsule IDs from previously loaded capsules\n",
        "\n",
        "rare_ids = [cap.id for cap in loaded_capsules if cap.rare]\n",
        "\n",
        "# Print the number of rare capsules and a sample of their IDs\n",
        "print(f\"Number of rare capsules: {len(rare_ids)}\")\n",
        "print(\"Sample rare capsule IDs:\", rare_ids[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D2uEMzCe9VG",
        "outputId": "f54000d8-6a82-4248-bb90-667f6fc84121"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rare capsules: 59\n",
            "Sample rare capsule IDs: ['57c63db2-d90a-40ab-bd9d-b07396eeb7ea', '8b094014-ab80-44f0-a5e5-f86ac1b0be21', 'a37d4a5e-4364-4729-af6f-1963cd33d4b7', 'bd2690d0-df02-4f38-bc9e-ff9ecffe320b', 'a6cc3c6a-6a23-45dd-a982-211dd600fa73']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create and save the Model Capsule with metadata(rarity term updated)"
      ],
      "metadata": {
        "id": "BwUXphJNv9qM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7.2: Create the model capsule and save it\n",
        "\n",
        "model_capsule = ModelCapsule(\n",
        "    model_type=\"LogisticRegression\",\n",
        "    accuracy=acc,\n",
        "    capsule_ids=[cap.id for cap in loaded_capsules],\n",
        "    high_conf_capsules=high_conf_ids,\n",
        "    weights=weights_list,  # Changed from weights_list\n",
        "    intercept=intercept_val, # Changed from intercept_val\n",
        "    rare_capsules=rare_ids\n",
        ")\n",
        "\n",
        "# Save model capsule\n",
        "model_capsule.save(folder_path)"
      ],
      "metadata": {
        "id": "JrmtD1DHgFlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a50f34d-e1a9-4c82-a96c-21f2fe10687c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model capsule with weights to /content/drive/My Drive/Capsule/21a4f89e-d25d-4a54-9985-10346f735ce1_model_capsule.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Client Capsule State Table (Context Tracker)\n",
        "\n",
        "This component will be a dictionary or a small class per client storing:\n",
        "\n",
        "client_id\n",
        "\n",
        "capsule_ids_received (set of capsule UUIDs)\n",
        "\n",
        "rare_labels_missing (labels the client has rarely seen — optional)\n",
        "\n",
        "last_updated\n",
        "\n",
        "maybe: history of model capsule scores"
      ],
      "metadata": {
        "id": "pMB7AgFN1e5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClientContextTable:\n",
        "    def __init__(self, client_id=None):\n",
        "        self.client_id = client_id or str(uuid.uuid4())\n",
        "        self.received_capsule_ids = set()\n",
        "        self.rare_labels = set()\n",
        "        self.class_distribution = {}  # New\n",
        "        self.low_confidence_ids = set()  # New\n",
        "        self.last_updated = datetime.datetime.utcnow().isoformat()\n",
        "\n",
        "    def update_class_distribution(self, label_counts):\n",
        "        self.class_distribution = label_counts\n",
        "        self.last_updated = datetime.datetime.utcnow().isoformat()\n",
        "\n",
        "    def update_low_confidence_ids(self, low_conf_ids):\n",
        "        self.low_confidence_ids.update(low_conf_ids)\n",
        "        self.last_updated = datetime.datetime.utcnow().isoformat()\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"client_id\": self.client_id,\n",
        "            \"received_capsule_ids\": list(self.received_capsule_ids),\n",
        "            \"rare_labels\": list(self.rare_labels),\n",
        "            \"class_distribution\": self.class_distribution,\n",
        "            \"low_confidence_predictions\": list(self.low_confidence_ids),\n",
        "            \"last_updated\": self.last_updated\n",
        "        }\n"
      ],
      "metadata": {
        "id": "b16eK1DhyFZ2"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute class distribution"
      ],
      "metadata": {
        "id": "okLipYzd9Chl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Compute class distribution from local capsules\n",
        "label_counts = Counter([cap.label for cap in loaded_capsules])\n",
        "\n",
        "# Convert to standard dictionary (if needed)\n",
        "label_counts = dict(label_counts)\n",
        "\n",
        "# Update in client context\n",
        "client_ctx.update_class_distribution(label_counts)\n"
      ],
      "metadata": {
        "id": "pVQwZPUF9EZ0"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute Low confidence and rare labels"
      ],
      "metadata": {
        "id": "29HO4bGVAJml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "low_conf_ids = []\n",
        "\n",
        "for cap, x_feat, y_true in zip(loaded_capsules, X_capsules, y_capsules):\n",
        "    y_pred = clf.predict([x_feat])[0]\n",
        "    if y_pred != y_true:\n",
        "        low_conf_ids.append(cap.id)\n",
        "\n",
        "client_ctx.update_low_confidence_ids(low_conf_ids)\n",
        "\n",
        "rare_labels = list(set([cap.label for cap in loaded_capsules if cap.rare]))\n",
        "client_ctx.set_rare_labels(rare_labels)\n",
        "\n",
        "folder_path = \"/content/drive/My Drive/Capsule\"\n",
        "client_ctx.save(folder_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuYRuOz6AEHt",
        "outputId": "5ecb3c2e-1973-4afe-fed7-8dec6bf6a19f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved context table to /content/drive/My Drive/Capsule/client_1_context.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional Next Steps (Later Stages)\n",
        "Once you have multiple clients or simulated sharing:\n",
        "\n",
        "Use rare_labels to prioritize what the client needs\n",
        "\n",
        "Use received_capsule_ids to avoid duplicate reception\n",
        "\n",
        "Use class_distribution to choose capsules to send (diversity or class balance)\n",
        "\n",
        "Use low_confidence_ids to refine local training"
      ],
      "metadata": {
        "id": "B_Y2oS1BBRQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QcFRJbxY1eFi"
      }
    }
  ]
}